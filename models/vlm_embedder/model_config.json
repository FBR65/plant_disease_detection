{
  "model_name": "openai/clip-vit-base-patch32",
  "embedding_dim": 512,
  "processor_config": {
    "image_size": 224,
    "image_mean": [0.48145466, 0.4578275, 0.40821073],
    "image_std": [0.26862954, 0.26130258, 0.27577711]
  },
  "text_config": {
    "max_length": 77,
    "truncation": true,
    "padding": true
  },
  "description": "CLIP-Modell f√ºr multimodale Embeddings von Pflanzenbildern"
}
