# ğŸŒ± Plant Disease Detection

Ein umfassendes System zur Erkennung von Pflanzenkrankheiten mittels PyTorch und Vision-Language Models (VLM).

## ğŸ¯ Universelle Anwendbarkeit

**Dieses System ist als generische Vorlage fÃ¼r KI-basierte Bildanalyse und intelligente Suchsysteme konzipiert.** Die Architektur kombiniert trainierte Machine Learning-Modelle mit Vision-Language Models (VLM) und Vector-Datenbanken zu einem flexiblen Framework, das auf verschiedenste AnwendungsfÃ¤lle Ã¼bertragbar ist:

- **ğŸ”„ Modular aufgebaut**: Austauschbare Komponenten fÃ¼r Datenverarbeitung, Modellerstellung und Inferenz
- **ğŸ¨ Domain-agnostisch**: Einfache Anpassung an beliebige Bildklassifikations-Aufgaben (Medizin, Industrie, Einzelhandel, etc.)
- **ğŸš€ Produktionsreif**: Robuste Datenverarbeitung, Fehlerbehandlung und skalierbare Deployment-Optionen
- **ğŸ” Intelligente Suche**: VLM-Embeddings ermÃ¶glichen semantische Ã„hnlichkeitssuche Ã¼ber DomÃ¤nen hinweg
- **ğŸ’¾ Skalierbare Persistierung**: Vector-Database-Integration fÃ¼r groÃŸe Datenmengen und Echtzeit-Abfragen

Die **Pflanzenkrankheitserkennung** dient als praktisches Beispiel und Referenzimplementierung. Die gleiche Architektur kann fÃ¼r QualitÃ¤tskontrolle in der Fertigung, medizinische Bilddiagnostik, Produktklassifikation im E-Commerce oder beliebige andere Computer Vision-Aufgaben eingesetzt werden.

## ğŸ“‹ ProjektÃ¼bersicht

Dieses Projekt implementiert ein **produktionsreifes** System zur automatischen Erkennung von z. B. Pflanzenkrankheiten mit folgenden Hauptfunktionen:

- **ğŸ¯ Intelligente Klassifikation**: PyTorch-basierte Deep Learning-Modelle mit automatischem Klassenbalancing
- **ğŸ”„ Adaptive Datenaugmentation**: Synthetische Bilderzeugung fÃ¼r Minderheitsklassen (lÃ¶st 89:1 Ungleichgewicht)
- **ğŸ“Š DatenqualitÃ¤ts-Analyse**: Automatische Erkennung von Problemen (GrÃ¶ÃŸenvariation, Klassenungleichgewicht)
- **âš–ï¸ Smart Sampling**: WeightedRandomSampler fÃ¼r ausbalancierte Training-Batches
- **ğŸŒ Moderne Web-UI**: Gradio-basierte BenutzeroberflÃ¤che fÃ¼r einfache Nutzung
- **ğŸ” Ã„hnlichkeitssuche**: VLM-basierte Embeddings fÃ¼r Ã¤hnliche Bilder (geplant)
- **ğŸ’¾ Vector Database**: Qdrant-Integration fÃ¼r skalierbare Suche (geplant)

## ğŸ—ï¸ Projektstruktur

```
plant_disease_detection/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ PlantDoc/               # PlantDoc-Dataset
â”‚       â”œâ”€â”€ train/              # Trainingsbilder
â”‚       â”‚   â”œâ”€â”€ healthy/
â”‚       â”‚   â”œâ”€â”€ disease_A/
â”‚       â”‚   â””â”€â”€ disease_B/
â”‚       â””â”€â”€ test/               # Testbilder
â”‚           â”œâ”€â”€ healthy/
â”‚           â”œâ”€â”€ disease_A/
â”‚           â””â”€â”€ disease_B/
â”œâ”€â”€ src/                        # Quellcode (Python-Module)
â”‚   â”œâ”€â”€ data_exploration.py     # Erweiterte Datenanalyse mit Balancing-Empfehlungen
â”‚   â”œâ”€â”€ advanced_augmentation.py # Intelligente Datenaugmentation & Klassenbalancing
â”‚   â”œâ”€â”€ train.py               # PyTorch-Trainingsskript
â”‚   â”œâ”€â”€ gradio_app.py          # Gradio-Webanwendung
â”‚   â”œâ”€â”€ model.py               # Modellarchitekturen
â”‚   â”œâ”€â”€ data_loader.py         # Datenlade- und Vorverarbeitungsklassen (Legacy)
â”‚   â”œâ”€â”€ vlm_utils.py           # VLM-Embedding-Funktionen
â”‚   â””â”€â”€ qdrant_handler.py      # Qdrant-Integration
â”œâ”€â”€ models/                     # Trainierte Modelle
â”‚   â”œâ”€â”€ classification_model/
â”‚   â”‚   â”œâ”€â”€ model.pth
â”‚   â”‚   â””â”€â”€ classes.json
â”‚   â””â”€â”€ vlm_embedder/
â”‚       â””â”€â”€ model_config.json
â”œâ”€â”€ config/                     # Konfigurationsdateien
â”‚   â”œâ”€â”€ dataset_config.yaml
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ qdrant_config.yaml
â”œâ”€â”€ tests/                      # Unit Tests
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ reports/                    # Berichte und Visualisierungen
â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â””â”€â”€ training_history.png
â”œâ”€â”€ pyproject.toml              # Python-AbhÃ¤ngigkeiten (uv-kompatibel)
â”œâ”€â”€ README.md                   # Projektdokumentation
â””â”€â”€ .gitignore                  # Git-Ignore-Datei
```
PlantDoc Dataset: https://paperswithcode.com/dataset/plantdoc

## ğŸš€ Schnellstart

### 1. Installation

```bash
# Repository klonen
git clone <repository-url>
cd plant_disease_detection

# Virtual Environment mit uv erstellen
uv venv
source .venv/bin/activate  # Linux/Mac
# oder
.venv\Scripts\activate     # Windows

# AbhÃ¤ngigkeiten installieren
uv sync
```

### 2. Daten vorbereiten

```bash
# PlantDoc-Dataset in folgende Struktur bringen:
# data/PlantDoc/train/{klasse1,klasse2,...}/
# data/PlantDoc/test/{klasse1,klasse2,...}/

# Datenexploration ausfÃ¼hren
uv run explore-data
```

### 3. Modell trainieren

```bash
# PyTorch-basiertes Training starten
uv run train-model
```

### 4. Web-App starten

```bash
# Gradio-App starten
uv run run-app
```

## ğŸ“Š VerfÃ¼gbare Kommandos

### ğŸ” Erweiterte Datenanalyse
```bash
# VollstÃ¤ndige Datenexploration mit Balancing-Empfehlungen
uv run explore-data

# Ergebnis: Automatische Erkennung von Klassenungleichgewicht (89:1 Ratio)
# + Empfehlungen fÃ¼r Augmentation und Sampling-Strategien
```

### ğŸ”„ Intelligentes Training
```bash
# Training mit automatischem Klassenbalancing
uv run train-model

# Features:
# - Automatische MinoritÃ¤tsklassen-Erkennung
# - Synthetische Bilderzeugung (3x Faktor)
# - WeightedRandomSampler fÃ¼r ausbalancierte Batches
# - Adaptive Augmentation (stÃ¤rker fÃ¼r kleine Klassen)
```

### ğŸŒ Web-Anwendung
```bash
# Gradio-App mit verbesserter UI
uv run run-app

# Features:
# - Drag & Drop Bildupload
# - Real-time Klassifikation  
# - Konfidenz-Anzeige
# - Beispielbilder-Galerie
```

## ğŸ› ï¸ Technologie-Stack

### Core ML Framework
- **PyTorch 2.0+** - Deep Learning Framework (Windows-kompatibel)
- **torchvision** - Computer Vision Utilities
- **transformers** - Hugging Face Transformers fÃ¼r VLM

### Computer Vision
- **Pillow** - Bildverarbeitung
- **OpenCV** - Computer Vision Operations
- **albumentations** - Datenaugmentation

### Web Interface
- **Gradio** - Moderne Web-UI fÃ¼r ML-Modelle
- **FastAPI** - REST API Backend (optional)

### Database & Storage
- **Qdrant** - Vector Database fÃ¼r Ã„hnlichkeitssuche
- **HDF5** - Effiziente Datenspeicherung

### Development Tools
- **uv** - Schneller Python Package Manager
- **ruff** - Code Formatting

## ğŸ”§ Konfiguration

### Dataset-Konfiguration (`config/dataset_config.yaml`)
```yaml
data_path: "data/PlantDoc"
image_processing:
  target_size: [224, 224]
  normalization: "imagenet"
dataloader:
  batch_size: 32
  num_workers: 4
classes:
  # Automatisch aus Ordnerstruktur erkannt
```

### Model-Konfiguration (`config/model_config.yaml`)
```yaml
architecture: "resnet50"
pretrained: true
num_classes: auto  # Automatisch erkannt
training:
  epochs: 25
  learning_rate: 0.001
  batch_size: 32
  optimizer: "adam"
```

### Qdrant-Konfiguration (`config/qdrant_config.yaml`)
```yaml
connection:
  host: "localhost"
  port: 6333
collection:
  name: "plant_disease_embeddings"
  vector_size: 512
```

### Klassenbalancing-Konfiguration

```yaml
# Erweiterte Augmentation-Konfiguration
augmentation:
  # Automatisches Balancing
  enable_synthetic_generation: true
  synthetic_factor: 3              # 3x mehr Samples fÃ¼r Minorities
  minority_threshold: 0.5          # < 50% der max. KlassengrÃ¶ÃŸe
  
  # Weighted Sampling
  use_weighted_sampling: true
  
  # Augmentation-StÃ¤rke
  strong_augmentation_for_minorities: true
  
  # Transformationen
  image_size: 224
  resize_intermediate: 256
  geometric_transforms:
    rotation_limit: 30
    horizontal_flip: 0.5
    vertical_flip: 0.2
  
  photometric_transforms:
    brightness_limit: 0.2
    contrast_limit: 0.2
    hue_shift_limit: 10
    
  plant_specific:
    random_shadow: 0.3
    sun_flare: 0.1
    color_jitter: 0.3
```

## ğŸ“Š DatenqualitÃ¤ts-Features

### Automatische Problemerkennung

Das System analysiert automatisch Ihren Datensatz und identifiziert:

```bash
uv run explore-data
```

**Erkannte Probleme (PlantDoc-Beispiel):**
- ğŸš¨ **Kritisches Ungleichgewicht**: 89.5:1 Ratio (179 vs 2 Samples)
- ğŸ“ **Extreme GrÃ¶ÃŸenvariation**: 143-5472px Breite (38x Unterschied)
- âš ï¸ **Problematische Klasse**: "Tomato two spotted spider mites leaf" (nur 2 Bilder)

**Automatische LÃ¶sungsvorschlÃ¤ge:**
```
ğŸ’¡ EMPFEHLUNGEN:
ğŸ”„ DATENAUGMENTATION:
  - Synthetische Bilder fÃ¼r Minderheitsklassen generieren
  - Faktor 2-5x Augmentation fÃ¼r kleine Klassen
  
âš–ï¸ SAMPLING STRATEGIEN:
  - WeightedRandomSampler fÃ¼r Klassenbalancing
  - Focal Loss fÃ¼r schwierige Klassen
  
ğŸš¨ KRITISCHES UNGLEICHGEWICHT:
  - Evaluation-Metriken: Precision/Recall statt Accuracy
```

### Intelligente Datenerweiterung

**Vor dem Balancing:**
```
Tomato two spotted spider mites leaf: 2 Samples    âš ï¸
Corn leaf blight: 179 Samples                      ğŸ“ˆ
Ratio: 89.5:1 (kritisch)
```

**Nach automatischem Balancing:**
```
Tomato two spotted spider mites leaf: 82+ Samples  âœ…
Corn leaf blight: 179 Samples                      ğŸ“ˆ  
Ratio: ~2:1 (ausbalanciert)
```

### Produktionsreife Features

- **ğŸ“Š DatenqualitÃ¤ts-Dashboard**: Automatische Analyse und Visualisierung
- **ğŸ”„ Adaptive Augmentation**: StÃ¤rke basierend auf KlassengrÃ¶ÃŸe
- **âš–ï¸ Smart Sampling**: WeightedRandomSampler + Stratified Sampling  
- **ğŸ¯ Evaluation-Metriken**: Precision/Recall/F1 fÃ¼r unbalancierte Daten
- **ğŸ’¾ Caching**: Intelligentes Speichern verarbeiteter Bilder

## ğŸ§ª Tests ausfÃ¼hren

```bash
# Alle Tests
python -m pytest tests/ -v

# Spezifische Tests
python -m pytest tests/test_data_loader.py -v
python -m pytest tests/test_model.py -v
```

## ğŸ“ˆ Modellarchitekturen

Das System unterstÃ¼tzt verschiedene vortrainierte Modelle:

- **ResNet50**: BewÃ¤hrte Architektur, gute Balance zwischen Genauigkeit und Geschwindigkeit
- **EfficientNetB0**: Effiziente Architektur mit geringem Speicherbedarf
- **VGG16**: Klassische Architektur, robust aber langsamer

### Transfer Learning
Alle Modelle verwenden Transfer Learning mit ImageNet-vortrainierten Gewichten:
1. Frozen Base Model Training (Initial)
2. Fine-tuning (Optional)

## ğŸ” VLM-Integration

Das System nutzt CLIP (Contrastive Language-Image Pre-training) fÃ¼r:
- Multimodale Embeddings (Bild + Text)
- Ã„hnlichkeitssuche
- Zero-shot Klassifikation

### UnterstÃ¼tzte VLM-Modelle
- `openai/clip-vit-base-patch32` (Standard)
- Weitere CLIP-Varianten Ã¼ber Konfiguration

## ğŸ—„ï¸ Vector Database (Qdrant)

Qdrant wird fÃ¼r skalierbare Ã„hnlichkeitssuche verwendet:

### Setup
```bash
# Qdrant mit Docker starten
docker run -p 6333:6333 qdrant/qdrant

# Oder lokale Installation
pip install qdrant-client
```

### Funktionen
- Embedding-Speicherung
- Cosinus-Ã„hnlichkeitssuche
- Metadaten-Filterung
- Batch-Operations

## ğŸŒ Web-Interface

Die Streamlit-App bietet:
- Drag & Drop Bild-Upload
- Echtzeit-Klassifikation
- Ã„hnlichkeitssuche-Visualisierung
- Konfidenz-Scores
- Model-Performance-Metriken

### Features
- ğŸ“¤ **Bild-Upload**: UnterstÃ¼tzt JPG, PNG
- ğŸ” **Klassifikation**: Echtzeit-Krankheitserkennung
- ğŸ¯ **Ã„hnlichkeitssuche**: Finde Ã¤hnliche FÃ¤lle
- ğŸ“Š **Visualisierung**: Interaktive Ergebnisdarstellung

## ğŸ”¬ Erweiterte Features

### Automatisches Klassenbalancing

Das System erkennt automatisch Klassenungleichgewichte und behebt diese:

```bash
# Erweiterte Datenexploration mit Balancing-Empfehlungen
uv run explore-data
```

**Automatische Problemerkennung:**
- âš–ï¸ **Klassenungleichgewicht-Analyse** (Ratio-Berechnung)
- ğŸ“ **BildgrÃ¶ÃŸen-Variation** (119-6000px Breite erkannt)
- ğŸ¯ **Minderheitsklassen-Identifikation** (< 50% der Median-KlassengrÃ¶ÃŸe)

**Intelligente LÃ¶sungen:**
- ğŸ”„ **Synthetische Bilderzeugung** fÃ¼r Minderheitsklassen
- âš–ï¸ **WeightedRandomSampler** fÃ¼r ausbalancierte Batches  
- ğŸ¨ **Adaptive Augmentation** (stÃ¤rker fÃ¼r kleine Klassen)
- ğŸ“Š **Automatische GrÃ¶ÃŸen-Vereinheitlichung** (256â†’224px)

### Advanced Data Augmentation

```python
# Verwendung der erweiterten Augmentation
from src.advanced_augmentation import create_balanced_dataloader

# Automatisch ausbalancierter DataLoader
train_loader, dataset = create_balanced_dataloader(
    data_dir="data/PlantDoc",
    split="train",
    augment_minority_classes=True,  # Synthetische Bilder fÃ¼r kleine Klassen
    synthetic_factor=3,             # 3x mehr Augmentation fÃ¼r Minorities
    use_weighted_sampling=True      # Balanced Sampling
)
```

**Augmentation-Pipeline:**
- ğŸŒ± **Pflanzen-spezifisch**: RandomShadow, SunFlare, ColorJitter
- ğŸ”„ **Geometrisch**: Rotation, Flip, ElasticTransform, GridDistortion
- ğŸ¨ **Photometrisch**: Brightness, Contrast, Hue, Saturation
- ğŸ” **QualitÃ¤t**: GaussNoise, GaussianBlur, CLAHE
- ğŸ“ **Normalisierung**: ImageNet-Standards (mean/std)

**Beispiel-Ergebnis fÃ¼r PlantDoc:**
```
Klasse 'Tomato two spotted spider mites leaf': 2 â†’ 80+ Samples
Automatisch: 89.5:1 Ratio â†’ 4:1 Ratio (ausbalanciert)
```

## ğŸ› ï¸ Entwicklung

### Code-Struktur
```python
# Datenloader
from src.data_loader import PlantDiseaseDataLoader

# Modell
from src.model import PlantDiseaseClassifier

# VLM-Embeddings
from src.vlm_utils import PlantDiseaseEmbedder

# Qdrant-Integration
from src.qdrant_handler import QdrantHandler
```

### Neue Krankheitsklassen hinzufÃ¼gen
1. Datenordner erstellen: `data/raw/train/neue_krankheit/`
2. Konfiguration anpassen: `config/dataset_config.yaml`
3. Modell neu trainieren

### Custom Modellarchitekturen
Erweitere `src/model.py` fÃ¼r neue Architekturen:
```python
def create_custom_model(input_shape, num_classes):
    # Deine Modellarchitektur
    pass
```

## ğŸ“Š Performance & Monitoring

### Metriken
- **Accuracy**: Klassifikationsgenauigkeit
- **Precision/Recall**: Pro Klasse
- **F1-Score**: Harmonisches Mittel
- **Confusion Matrix**: Detaillierte Fehleranalyse

### Logging
- Training-Logs: `models/classification_model/logs/`
- Modell-Checkpoints: `models/classification_model/checkpoint/`
- Ergebnisse: `models/classification_model/training_results.yaml`

## ğŸ¤ Beitragen

1. Fork das Repository
2. Erstelle einen Feature-Branch: `git checkout -b feature/neue-funktion`
3. Commit deine Ã„nderungen: `git commit -am 'Neue Funktion hinzugefÃ¼gt'`
4. Push zum Branch: `git push origin feature/neue-funktion`
5. Erstelle einen Pull Request

## ğŸ“„ Lizenz

Dieses Projekt steht unter der AGPLv3-Lizenz. Siehe `LICENSE` Datei fÃ¼r Details.

## ğŸ†˜ Support

Bei Fragen oder Problemen:
1. ÃœberprÃ¼fe die [Issues](../../issues)
2. Erstelle ein neues Issue mit detaillierter Beschreibung
3. Verwende die bereitgestellten Log-Dateien fÃ¼r Debugging

## ğŸ”— NÃ¼tzliche Links

- [TensorFlow Documentation](https://www.tensorflow.org/api_docs)
- [CLIP Model Documentation](https://huggingface.co/openai/clip-vit-base-patch32)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Streamlit Documentation](https://docs.streamlit.io/)

---

**Erstellt fÃ¼r die moderne Pflanzenkrankheitserkennung mit KI** ğŸŒ±ğŸ¤–